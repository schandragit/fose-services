\section{Risk identification and management}


Software risk management is a well established discipline~\cite{risk1,risk2} that has generated continued academic interest as the complexity and nature of the software projects have evolved over time. Traditional risk management techniques have been focused on identifying and codifying best practices that prevent or reduce the failure rate~\cite{risk3,risk4,risk5,risk6,risk7}. Large IT organizations have assimilated many of these findings in their risk management practice.  However, adopting these best practices does not guarantee that risk is eliminated or even reduced to an acceptable level -- new software development models driven by globalization, competition and an ever changing software landscape throw up new patterns of trouble.

In recent literature, the trend towards a systems approach to risk management, where in statistical techniques are used to classify and mine the project metrics data, with a view to pro-actively learn the new trends is gaining acceptance~\cite{risk8,risk9,risk10}.  These methods actively use the metrics collected during traditional risk management reviews and then employ techniques borrowed from statistical learning theory to derive models that describe the relationship between the collected metrics and eventual project outcomes. Thus, certain patterns of values in project metrics can act as alerts, which can be then used to initiate further reviews to see whether the alert was justified. It is important to note that these techniques in most cases cannot identify why a project may be troubled i.e., they can only serve as a starting point for further investigation.  Another significant short coming of these models is their inability to implicitly account for outliers and missing data -- for example, a project in good health will not typically have as thorough a review as a project in trouble9. Unless the data that is used to train the model is carefully validated to account for these characteristic patterns, there is a good chance that the model will not be very accurate. This problem is particularly prevalent in large IT delivery organizations which typically exhibit a large variance in both the quality of the metrics collected and reporting patterns.

Functionality risk is defined as the risk that the completed system will not meet its user's needs~\cite{risk11}.  It is the risk that churn in business requirements and scope combined with ineffective communication mechanisms leads to the development of working software that is essentially useless to the end user~\cite{risk12}. In a recent article~\cite{risk13}, it has been argued that functionality risk has become an increasingly important factor due to the challenges  that globalization has created. Through empirical analysis, they identify that development methodology fit, customer involvement, and use of formal project management practices as the top three functionality risk factors. In complex IT engagements we find that reducing or eliminating functionality risk, which in turn leads to high customer satisfaction, may result in an unacceptable increase in other risk factors such as financial risk for the provider. Thus, in our approach we opt to look for trouble patterns across a broad spectrum of risk indicators and surface problems which then allow risk managers to make informed decisions.

Quantitative analysis of IT investment decisions using options analysis, to mitigate financial risk, is an active area of research~\cite{14,15,16}. Options analysis can be used to assess the value of prototyping work and early adoption initiatives related to new IT platforms – options provide a way to evaluate the value of IT projects which give the right to adopt the resulting technology without having the obligation to do so. Fichman~\cite{risk14} shows how options analysis can be used to predict IT platform initiation and adoption, value IT platform options and manage IT platform implementation. Chen and Sheng~\cite{risk15} discuss how to do real options analysis while accounting for estimation errors. However, the ability to use the results of the analysis in a dispassionate manner to start and cull IT projects is still a contentious topic~\cite{risk17}. As Keil et al.~\cite{risk18} observe, there is a strong bias in many organizations to continue with IT projects even though financial analysis indicates otherwise. In our view, the lack of widespread adoption for options analysis can be traced back to a fundamental issue that effects all methods for analyzing financial risk – the inability to accurately estimate with any degree of certainty the net present value (NPV) of a complex in-flight IT project. In this paper,  we evaluate financial risk by analyzing how projects that exhibited similar trends in project metrics performed in the past – thus, the analysis has no dependence on a particular methodology for evaluating NPV.

Evaluating IT project portfolios with a view to making strategic decisions that help the portfolio grow in accordance with business needs helps target limited budgets on relevant projects. Armour~\cite{risk18} argues that a company’s IT project portfolio should be treated like any other investment portfolio to understand whether the reward justifies the estimated risk. Given the uncertainty surrounding the estimation of risk, Lin~\cite{risk20} suggests that fuzzy logic may be used to make IT portfolio decisions. Holland and Fathi~\cite{risk25} suggest that uncertainty can be reduced through portfolio diversification and spreading the risk of incorrect risk management decisions across a wide pool of projects. Our approach to surfacing trouble indicators provides tools for a company to make strategic decisions about its IT project portfolio.

Erickson and Evaristo~\cite{risk22} provide an account of how risk factors associated with IT projects are magnified or multiplied when dealing with distributed project teams.  They provide a conceptual list of a variety of factors ranging from culture to distance and discuss how an increase in distributedness along these dimensions affects project risk.  Ramasubbu and Balan~\cite{risk23} present an empirical study which quantifies the loss in quality and increase in schedule risk that one would expect in global software projects. They suggest that good software process controls may mitigate these losses to some degree. Beise~\cite{risk24} suggests that good project management practices when properly applied may help to mitigate some of the problems caused by virtual teams. Our analysis suggests that even under the best possible control structure the losses due to distributed development are unavoidable -- the ability to recognize the symptoms and act quickly will decide which  companies will succeed in leveraging the promise of globalization.

It is well known that decision-makers, including those in the risk management community, routinely use flawed heuristics in decision-making, which are subject to systematic biases~\cite{risk27}. Heemstra~\cite{risk24} analyzes how filters and biases of personnel involved in judging a project may prevent an accurate risk assessment. He suggests a team based decision making approach to avoid being heavily influenced by particular individuals. Host and Lindholm~\cite{risk25}  do an empirical analysis of how a set of identified project risks are weighted by different individuals. They find a wide variance in the perceived importance attached to individual risk factors -- however, they could not explain this variance on the basis of the particular role played by the person in the project. Maytorena~\cite{risk26} provides an interesting study on the effect of experience on the ability of project managers to recognize certain risk factors. It shows that experience does not have a significant impact on the ability to detect risk as do other factors like risk management training, ability to quickly grasp information and the level of education. In practice, we find that packaging the statistical information and trouble patterns in an easily understandable and actionable fashion to the risk managers may be as important as the information itself.

\subsection{Risk prediction}
 In any complex software development project, a number of risk assessment related activities are conducted prior to project inception with an objective of determining the risk entailed in delivery. The number and depth of these reviews is determined by a variety of factors, such as: the size of the project, the novelty of the proposed solution, and the industry sector to which the client belongs. These reviews may cross multiple delivery organizations within and beyond the purview of the primary service provider who is responsible for the delivery of the integrated software solution. Even for a large services provider that performs thousands of software projects with a variety of clients, it is not clear that there is infact a common set of criteria to judge the risk involved in these projects due to the great diversity in the projects and the client context in which they are executed. In this section, we will describe an approach to this problem of risk identification which has proven to be highly reliable and has been thoroughly tested in the field over the last five years.

 By reviewing the risk management reviews of several recent IT delivery projects, we identified a set of sixteen questions that were considered to be predictive of the project outcome in the initial phases of the project life cycle. These were then whetted by experienced risk managers and carefully screened to ensure that they can be used to obtain clearly defined answers within well-defined ranges. The intent was to remove subjectivity in the answers by basing them on data that is readily accessible to the risk manager.  Questions ranged from a client's past experience with the delivery organization, match of the delivery team’s technical skills to the project objectives and the type of contract (fixed price vs. time and materials).  A key point to be noted is that these questions do not delve deeply into the technical details of the project itself, as they need to cover a variety of IT projects ranging from implementing a custom application to customizing a packaged application. However, all the questions have proven to be highly correlated with the eventual outcome of the project.

 The traditional risk management approach was to scale the answers for these set of questions for a given project, sum the scaled answers and apply threshold(s)/range(s) on the result which can be then associated with a given outcome of a projected future project management review based on correlation with historical data. However, the pitfalls in such an approach are clear – dependencies/interactions between sets of questions may lead to inconsistent results over a broad set of projects. For example, a “fixed price” deal combined with a novel (first of a kind) technical solution may be more risky to undertake than a “time and materials” deal in the same context. Figure~\ref{riskfig1} shows the relationship between a simple scaled average and the project management review letter grade of over 130 real software projects (in this example, project risk significantly increases as the letter grade increases from A to D). It is clear that the choice of any given set of thresholds would lead to a misclassification of a number of projects.

 <<Risk Figure 1>>

 We took an alternative approach where we used statistical classification algorithms to match the risk management questions with the eventual project outcome~\cite{risk28}. Prior to classification, the answers to the risk management review questions were scaled and binned appropriately to reduce the effects of variance due to human error and differences in procedures followed in different countries. For example, a question about the number of customer contacts prior to the signing of the deal was reduced to three classes – high, medium and low rather than asking for an exact number (since the definition of a customer contact can be interpreted and even tallied differently by different risk managers). We chose to apply a decision tree classifier to the data set, as this approach not only produced acceptable results, but the resultant rules make the prediction process transparent to the end users. We split the available data set into a training and test data set through random sampling. Figure~\ref{riskfig2} shows the cost and misclassification matrices for this approach. The cost matrix allows the risk managers to indicate the relative weight to be associated with a particular type of misclassification. For example, the cost matrix shows that misclassifying a project that would have been a C as a D project carries a weight of 1, where as a more serious misclassification of C as an A carries a weight of 9. As can be seen, false positives (good projects being classified as troubled) carry less weight than false negatives (troubled projects being classified as good). The classification matrix shows how each category of projects fared in terms of prediction. As expected, the number of false negatives (3\%) is less than the number of false positives (7\%) and more than 94\% of the troubled projects (C/D) are captured by the classification scheme.
 
<<Risk Figure 2>>


\label{sec:risk}
