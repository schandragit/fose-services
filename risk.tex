\section{Risk Management}

Software risk management is a well established discipline~\cite{risk1,risk2} that has generated continued academic interest as the complexity and nature of the software projects have evolved over time. Risk management for software product development involves a different set of considerations than developing custom software solutions for individual consumers. The latter is more challenging and will be the focus of this section. Despite best efforts, dramatic failures are quite common in large custom software development projects. We will discuss the state of the art in risk management and some open problems that need to be addressed.

\subsection{Research areas}

Traditional risk management techniques have been focused on identifying and codifying best practices that prevent or reduce the failure rate~\cite{risk3,risk4,risk5}. Large IT organizations have assimilated many of these findings in their risk management practice.  It is however common to encounter ever growing checklists of problem areas and best practices in these enterprises which eventually makes them ineffectual. We also find that adopting these best practices does not guarantee that risk is eliminated or even reduced to an acceptable level -- new software development models driven by globalization, competition and an ever changing software landscape throw up new patterns of trouble. Focused context dependent risk management, potentially aided by analytical approaches, is needed to reduce the overhead and make the process more effective.

Risk management may also have different connotations for providers and consumers. For providers, the goal is to improve financial outcomes while maintaining high customer satisfaction. For consumers, the goal is to obtain functional software that meets the business requirements while avoiding cost overruns. Although there is a shared goal of building useful software for the end consumer, optimal risk mitigation actions may be different for these two parties. A key focus of academic risk management literature is to reduce functionality risk~\cite{risk11}.  It is the risk that churn in business requirements and scope combined with ineffective communication mechanisms leads to the development of working software that is essentially useless to the end user~\cite{risk12}. In complex IT engagements we find that completely eliminating functionality risk, which in turn may lead to high customer satisfaction, may result in an unacceptable increase in other risk factors such as financial risk for the provider. We believe that the best approach is to look for trouble patterns across a broad spectrum of risk indicators and surface problems which then allow risk managers to make informed decisions. We can potentially use big data analytics to look at the trajectory of a project that can detect statistically relevant patterns as opposed to structured approaches which rely on painstakingly tabulating risk factors.

It is well known that decision-makers, including those in the risk management community, routinely use flawed heuristics in decision-making, which are subject to systematic biases~\cite{risk27}. Heemstra~\cite{risk24} analyzes how filters and biases of personnel involved in judging a project may prevent an accurate risk assessment. He suggests a team based decision making approach to avoid being heavily influenced by particular individuals. Host and Lindholm~\cite{risk25}  do an empirical analysis of how a set of identified project risks are weighted by different individuals. They find a wide variance in the perceived importance attached to individual risk factors -- however, they could not explain this variance on the basis of the particular role played by the person in the project. Maytorena~\cite{risk26} provides an interesting study on the effect of experience on the ability of project managers to recognize certain risk factors. It shows that experience does not have a significant impact on the ability to detect risk as do other factors like risk management training, ability to quickly grasp information and the level of education. In practice, we find that packaging this information in an easily understandable and actionable fashion to the decision makers is as important as surfacing risks accurately.

Quantitative analysis of IT investment decisions using options analysis, to mitigate financial risk, is an active area of research~\cite{risk14,risk15,risk16}. Options analysis can be used to assess the value of prototyping work and early adoption initiatives related to new IT platforms -- options provide a way to evaluate the value of IT projects which give the right to adopt the resulting technology without having the obligation to do so. Fichman~\cite{risk14} shows how options analysis can be used to predict IT platform initiation and adoption, value IT platform options and manage IT platform implementation. Chen and Sheng~\cite{risk15} discuss how to do real options analysis while accounting for estimation errors. However, the ability to use the results of the analysis in a dispassionate manner to start and cull IT projects is still a contentious topic~\cite{risk17}. As Keil et al.~\cite{risk18} observe, there is a strong bias in many organizations to continue with IT projects even though financial analysis indicates otherwise. In our view, the lack of widespread adoption for options analysis can be traced back to a fundamental issue that effects all methods for analyzing financial risk -- the inability to accurately estimate with any degree of certainty the net present value (NPV) of a complex in-flight IT project. One option is to evaluate relative financial risk by analyzing how projects that exhibited similar trends in project metrics performed in the past. Thus, the analysis has no dependence on a particular methodology for evaluating NPV.

In recent literature, the trend towards a systems approach to risk management, where in statistical techniques are used to classify and mine the project metrics data, with a view to pro-actively learn the new trends is gaining acceptance~\cite{risk8,risk9,risk10}.  These methods actively use the metrics collected during traditional risk management reviews and then employ techniques borrowed from statistical learning theory to derive models that describe the relationship between the collected metrics and eventual project outcomes. Thus, certain patterns of values in project metrics can act as alerts, which can be then used to initiate further reviews to see whether the alert was justified. It is important to note that these techniques in most cases cannot identify why a project may be troubled i.e., they can only serve as a starting point for further investigation.  Another significant short coming of these models is their inability to implicitly account for outliers and missing data -- for example, a project in good health will not typically have as thorough a review as a project in trouble. Unless the data that is used to train the model is carefully validated to account for these characteristic patterns, there is a good chance that the model will not be very accurate. This problem is particularly prevalent in large IT delivery organizations which typically exhibit a large variance in both the quality of the metrics collected and reporting patterns. Even for a large services provider that performs thousands of software projects with a variety of clients, it is not clear that there is infact a common set of criteria to judge the risk involved in these projects due to the great diversity in the projects and the client context in which they are executed.

\subsection{Quantitative Analysis: An example}

We will now describe an analytical approach to the problem of risk mitigation for an IT provider which has been used successfully in practice. Through an analysis of the risk management reviews of several recent IT delivery projects, we identified a set of questions that were considered to be predictive of the project outcome in the initial phases of the project life cycle. These were then whetted by experienced risk managers and carefully screened to ensure that they can be used to obtain clearly defined answers within well-defined ranges. The intent was to remove subjectivity in the answers by basing them on data that is readily accessible to the risk manager.  Questions ranged from a client's past experience with the provider's organization, match of the delivery team's technical skills to the project objectives and the type of contract (fixed price vs. time and materials).  A key point to be noted is that these questions do not delve deeply into the technical details of the project itself, as they need to cover a variety of IT projects ranging from implementing a custom application to customizing a packaged application.

We used statistical classification algorithms to model the eventual project outcome. Prior to classification, the answers to the risk management review questions were scaled and binned appropriately to reduce the effects of variance due to human error and differences in procedures followed in different countries. For example, a question about the number of customer contacts prior to the signing of the deal was reduced to three classes -- high, medium and low rather than asking for an exact number (since the definition of a customer contact can be interpreted and even tallied differently by different risk managers). We chose to apply a modified boosted decision tree classifier to the data set, as this approach not only produced acceptable results, but the resultant rules make the prediction process transparent to the end users. We split the available data set into a training and test data set through random sampling. The results showed that the analysis is both accurate (< 18\% false positives and < 12\% false negatives) and performs well in practice.

We tried similar analytical techniques to predict and manage risks in complex IT engagements within IBM over the last several years. IBM has publicly acknowledged in its 2012 annual investor's briefing that they derived an annual savings of 50 million dollars over the last three years by employing predictive analytics in the area of delivery excellence~\cite{ibm-investors-briefing}. Although we were able to predict risk, being able to manage it requires a deeper understanding of the root causes and the sensitivity of the measurable outcomes to changes in these causal factors.

\label{sec:risk}
